# Markov Chain
A simple exercise for the Computational Statistics course.

Description:

Suppose a person walks through points 1, 2 and 3 as follows:

(i) The starting point of the tour is drawn with equal probability, ie: P (start at 1) = P (start at 2) = P (start at 3).

(ii) From then on, he follows the transition matrix rule:

M = {{0,   2/3, 1/3},
  
     {1/4, 1/2, 1/4},
    
     {1/3, 1/3, 1/3}}
